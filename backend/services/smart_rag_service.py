"""
Smart RAG Service
Uses Gemini for intelligent query parsing and Neo4j graph for movie recommendations.
"""
import asyncio
from typing import List, Dict, Any, Optional, Tuple
from concurrent.futures import ThreadPoolExecutor
import time
from loguru import logger

from backend.services.gemini_query_service import gemini_query_service, ParsedQuery, QueryType, MOOD_TO_GENRES
from backend.services.graph_query_service import graph_query_service
from backend.services.neo4j_service import neo4j_service


class SmartRAGService:
    """
    Smart RAG service with:
    - Gemini-powered natural language parsing
    - Cypher query generation
    - Graph queries for structured searches (director, actor, genre)
    - Graph similarity for "movies like X" (multi-hop scoring)
    - Graceful handling of unsupported queries
    """
    
    def __init__(self):
        self._executor = ThreadPoolExecutor(max_workers=4)
        self._response_cache: Dict[str, Dict] = {}
        self._cache_ttl = 300  # 5 minutes
    
    async def process_query(
        self,
        query: str,
        context_limit: int = 10,
        use_cache: bool = True
    ) -> Dict[str, Any]:
        """
        Process a user query with Gemini-powered parsing.
        
        Args:
            query: User's natural language query
            context_limit: Maximum movies to return
            use_cache: Whether to use cached results
            
        Returns:
            Dict with answer, recommendations, and metadata
        """
        start_time = time.time()
        
        # Check cache
        cache_key = f"{query}:{context_limit}"
        if use_cache and cache_key in self._response_cache:
            cached = self._response_cache[cache_key]
            if time.time() - cached["timestamp"] < self._cache_ttl:
                logger.info(f"Cache hit for query: {query[:50]}...")
                return cached["response"]
        
        # Step 1: Parse query with Gemini
        loop = asyncio.get_event_loop()
        parsed = await loop.run_in_executor(
            self._executor,
            lambda: gemini_query_service.parse_query(query)
        )
        
        logger.info(f"Parsed query: type={parsed.query_type.value}, entities={parsed.extracted_entities}")
        
        # Step 2: Handle unsupported queries gracefully
        if not parsed.is_supported:
            response = self._generate_unsupported_response(query, parsed)
            elapsed = time.time() - start_time
            response["metadata"] = {
                "elapsed_ms": int(elapsed * 1000),
                "query_type": "unsupported",
                "reason": parsed.unsupported_reason
            }
            response["reasoning"] = self._build_unsupported_reasoning(parsed, elapsed)
            return response
        
        # Step 3: Execute the appropriate search
        results = []
        similarity_details = {}
        
        if parsed.query_type == QueryType.SIMILAR:
            # Use graph-based similarity search
            movie_title = parsed.extracted_entities.get("similar_to_movie", "")
            if movie_title:
                results, similarity_details = await self._run_similarity_search(
                    movie_title,
                    context_limit
                )
        else:
            # Execute generated Cypher query
            results = await self._run_cypher_query(parsed, context_limit)
        
        # Step 4: Generate response
        response = self._generate_response(query, results, parsed, similarity_details)
        
        elapsed = time.time() - start_time
        response["metadata"] = {
            "elapsed_ms": int(elapsed * 1000),
            "query_type": parsed.query_type.value,
            "entities": parsed.extracted_entities,
            "results_count": len(results)
        }
        
        # Add detailed reasoning for transparency
        response["reasoning"] = self._build_reasoning(
            parsed, results, similarity_details, elapsed
        )
        
        # Cache response
        if use_cache:
            self._response_cache[cache_key] = {
                "response": response,
                "timestamp": time.time()
            }
        
        logger.info(f"Query processed in {elapsed*1000:.0f}ms")
        return response
    
    async def _run_cypher_query(
        self,
        parsed: ParsedQuery,
        limit: int
    ) -> List[Dict[str, Any]]:
        """Execute the Cypher query generated by Gemini."""
        loop = asyncio.get_event_loop()
        
        try:
            # Use the graph query service methods based on extracted entities
            entities = parsed.extracted_entities
            
            # Handle mood by converting to genres
            mood = entities.get("mood")
            mood_genres = []
            if mood:
                # Normalize mood and get genres
                mood_lower = mood.lower().replace("-", " ").replace("_", " ")
                mood_genres = entities.get("mood_genres") or MOOD_TO_GENRES.get(mood_lower, [])
                logger.info(f"Mood '{mood}' mapped to genres: {mood_genres}")
            
            # Capture values for lambda closures
            director = entities.get("director")
            actor = entities.get("actor")
            genres = entities.get("genres")
            year_min = entities.get("year_min")
            year_max = entities.get("year_max")
            
            if director:
                results = await loop.run_in_executor(
                    self._executor,
                    lambda d=director, l=limit, ymin=year_min, ymax=year_max: graph_query_service.search_by_director(
                        d, limit=l, year_min=ymin, year_max=ymax
                    )
                )
            elif actor:
                results = await loop.run_in_executor(
                    self._executor,
                    lambda a=actor, l=limit: graph_query_service.search_by_actor(a, limit=l)
                )
            elif mood_genres and genres:
                # BOTH mood AND explicit genres - combine all genres
                combined_genres = list(set(mood_genres + genres))
                logger.info(f"Combined search: mood genres {mood_genres} + explicit genres {genres} = {combined_genres}")
                results = await loop.run_in_executor(
                    self._executor,
                    lambda g=combined_genres, l=limit, ymin=year_min, ymax=year_max: graph_query_service.search_by_genre(
                        g, limit=l, year_min=ymin, year_max=ymax, min_match=2
                    )
                )
            elif mood_genres:
                # Mood search - movie must have at least 2 of the mood genres
                logger.info(f"Mood search with genres: {mood_genres} (min 2 match)")
                results = await loop.run_in_executor(
                    self._executor,
                    lambda g=mood_genres, l=limit, ymin=year_min, ymax=year_max: graph_query_service.search_by_genre(
                        g, limit=l, year_min=ymin, year_max=ymax, min_match=2
                    )
                )
            elif genres:
                # Explicit genres - movie must have at least 2 of the genres
                logger.info(f"Genre search with genres: {genres} (min 2 match)")
                results = await loop.run_in_executor(
                    self._executor,
                    lambda g=genres, l=limit, ymin=year_min, ymax=year_max: graph_query_service.search_by_genre(
                        g, limit=l, year_min=ymin, year_max=ymax, min_match=2
                    )
                )
            elif year_min or year_max:
                results = await loop.run_in_executor(
                    self._executor,
                    lambda ymin=year_min, ymax=year_max, g=genres, l=limit: graph_query_service.search_by_year_range(
                        ymin or 1900, ymax or 2030, genres=g, limit=l
                    )
                )
            else:
                # Combined search or fallback - use mood_genres if available
                search_genres = mood_genres if mood_genres else genres
                results = await loop.run_in_executor(
                    self._executor,
                    lambda d=director, a=actor, g=search_genres, ymin=year_min, l=limit: graph_query_service.search_combined(
                        director=d, actor=a, genres=g, year_min=ymin, limit=l
                    )
                )
            
            # Add source marker
            for r in results:
                r["_source"] = "graph"
                r["_score"] = 1.0
            
            return results
            
        except Exception as e:
            logger.error(f"Cypher query execution error: {e}")
            return []
    
    async def _run_similarity_search(
        self,
        movie_title: str,
        limit: int
    ) -> Tuple[List[Dict[str, Any]], Dict[str, Any]]:
        """
        Execute graph-based similarity search.
        Uses multi-hop relationships: genres > actors > directors > era.
        """
        loop = asyncio.get_event_loop()
        
        try:
            # Run graph similarity with weighted scoring
            results, details = await loop.run_in_executor(
                self._executor,
                lambda: graph_query_service.find_similar_movies(
                    movie_title=movie_title,
                    limit=limit,
                    genre_weight=5.0,   # Highest priority
                    actor_weight=3.0,
                    director_weight=2.0,
                    era_weight=1.0      # Lowest priority
                )
            )
            
            # Add source marker
            for r in results:
                r["_source"] = "similarity"
                r["_score"] = r.get("_similarity_score", r.get("similarity_score", 0.5))
            
            return results, details
            
        except Exception as e:
            logger.error(f"Similarity search error: {e}")
            return [], {}
    
    def _generate_response(
        self,
        query: str,
        results: List[Dict],
        parsed: ParsedQuery,
        similarity_details: Dict = None
    ) -> Dict[str, Any]:
        """Generate natural language response."""
        if not results:
            return {
                "answer": self._generate_no_results_message(parsed),
                "recommendations": [],
                "suggestions": self._generate_suggestions(parsed)
            }
        
        # Build response
        answer = self._build_answer(query, results, parsed, similarity_details)
        
        # Format recommendations
        recommendations = [
            {
                "movie_id": r.get("movie_id"),
                "title": r.get("title"),
                "score": r.get("_score", r.get("vote_average", 0) / 10 if r.get("vote_average") else 0.5),
                "genres": r.get("genres", []),
                "year": r.get("release_year"),
                "rating": r.get("vote_average"),
                "overview": r.get("overview", "")[:200] if r.get("overview") else "",
                "poster_path": r.get("poster_path"),
                "match_reason": r.get("_match_reason", "")
            }
            for r in results
        ]
        
        suggestions = self._generate_suggestions(parsed, results)
        
        return {
            "answer": answer,
            "recommendations": recommendations,
            "suggestions": suggestions
        }
    
    def _generate_unsupported_response(
        self,
        query: str,
        parsed: ParsedQuery
    ) -> Dict[str, Any]:
        """Generate response for unsupported queries."""
        # Build helpful suggestions
        suggestions = [
            "Something scary",
            "Feel-good 90s movies",
            "Christopher Nolan movies",
            "Movies with Tom Hanks",
            "Movies like Inception"
        ]
        
        answer = f"""I understand you're looking for something specific, but I can't directly search for **{parsed.explanation}**.

**Why?** {parsed.unsupported_reason}

**What I CAN search for:**
- ðŸŽ¬ **Directors**: "Christopher Nolan movies"
- ðŸŒŸ **Actors**: "Films with Leonardo DiCaprio"
- ðŸŽ­ **Genres**: "Horror movies", "Sci-fi thrillers"
- ðŸ’« **Moods**: "Something scary", "Feel-good movies", "Dark thrillers"
- ðŸ“… **Years**: "90s comedies", "Movies from 2020"
- ðŸ”— **Similar movies**: "Movies like Inception"

Try one of the suggestions below!"""
        
        return {
            "answer": answer,
            "recommendations": [],
            "suggestions": suggestions
        }
    
    def _build_answer(
        self,
        query: str,
        results: List[Dict],
        parsed: ParsedQuery,
        similarity_details: Dict = None
    ) -> str:
        """Build a concise natural language answer - movie details shown in cards."""
        entities = parsed.extracted_entities
        count = len(results)
        
        # Build a short, clean response - movies will be shown as cards
        if parsed.query_type == QueryType.SIMILAR:
            source_movie = similarity_details.get("source_movie", entities.get("similar_to_movie", ""))
            return f"Found **{count} movies** similar to **{source_movie}**! ðŸŽ¬"
        elif entities.get("director"):
            return f"Found **{count} movies** by **{entities['director']}**! ðŸŽ¬"
        elif entities.get("actor"):
            return f"Found **{count} movies** featuring **{entities['actor']}**! ðŸŽ¬"
        elif parsed.query_type == QueryType.MOOD or entities.get("mood"):
            mood = entities.get("mood", "your mood")
            return f"Found **{count} {mood}** movies for you! ðŸŽ¬"
        elif entities.get("genres"):
            genres = " & ".join(entities["genres"][:2])
            return f"Found **{count} {genres}** movies! ðŸŽ¬"
        elif entities.get("year_min") and entities.get("year_max"):
            return f"Found **{count} movies** from **{entities['year_min']}-{entities['year_max']}**! ðŸŽ¬"
        elif entities.get("year_min"):
            return f"Found **{count} movies** from **{entities['year_min']}** onwards! ðŸŽ¬"
        else:
            return f"Found **{count} movies** for you! ðŸŽ¬"
    
    def _generate_no_results_message(self, parsed: ParsedQuery) -> str:
        """Generate message when no results found."""
        entities = parsed.extracted_entities
        
        if entities.get("similar_to_movie"):
            return f"I couldn't find the movie '{entities['similar_to_movie']}' in our database. Try checking the spelling or searching for another movie."
        elif entities.get("director"):
            return f"I couldn't find any movies directed by {entities['director']} in our database. Try checking the spelling or searching for another director."
        elif entities.get("actor"):
            return f"I couldn't find any movies with {entities['actor']}. Try a different actor name."
        else:
            return "I couldn't find movies matching your query. Try being more specific or use different keywords."
    
    def _generate_suggestions(
        self,
        parsed: ParsedQuery,
        results: List[Dict] = None
    ) -> List[str]:
        """Generate follow-up suggestions."""
        suggestions = []
        
        if results and len(results) > 0:
            top_movie = results[0]
            suggestions.append(f"Movies like {top_movie['title']}")
            
            if top_movie.get("genres"):
                genre = top_movie["genres"][0] if isinstance(top_movie["genres"], list) else top_movie["genres"]
                suggestions.append(f"More {genre} movies")
        
        entities = parsed.extracted_entities
        if entities.get("similar_to_movie"):
            suggestions.append("Show me something different")
        elif entities.get("director"):
            suggestions.append("90s thrillers")
        elif entities.get("genres"):
            suggestions.append("Add an actor to filter")
        
        suggestions.extend([
            "Top rated movies of all time",
            "Recommend something from the 90s"
        ])
        
        return suggestions[:4]
    
    async def chat(
        self,
        message: str,
        history: List[Tuple[str, str]],
        context_limit: int = 10
    ) -> Dict[str, Any]:
        """
        Chat interface with conversation history.
        """
        return await self.process_query(message, context_limit)
    
    def _build_reasoning(
        self,
        parsed: ParsedQuery,
        results: List[Dict],
        similarity_details: Dict,
        elapsed: float
    ) -> Dict[str, Any]:
        """Build detailed reasoning explanation for transparency."""
        reasoning = {
            "steps": [],
            "graph_traversal": None,
            "similarity_search": None,
            "gemini_analysis": None,
            "summary": ""
        }
        
        # Step 1: Gemini Query Parsing
        gemini_step = {
            "step": 1,
            "name": "Gemini Query Analysis",
            "description": "Used Gemini AI to understand your query and extract relevant entities",
            "result": {
                "query_type": parsed.query_type.value,
                "explanation": parsed.explanation,
                "extracted_entities": parsed.extracted_entities
            }
        }
        reasoning["steps"].append(gemini_step)
        reasoning["gemini_analysis"] = {
            "model": "gemini-1.5-flash",
            "parsed_type": parsed.query_type.value,
            "entities": parsed.extracted_entities
        }
        
        # Step 2: Query Execution
        if parsed.query_type == QueryType.SIMILAR:
            # Similarity search step
            sim_step = {
                "step": 2,
                "name": "Graph Similarity Search",
                "description": "Found similar movies using multi-hop graph relationships",
                "result": {
                    "source_movie": similarity_details.get("source_movie", parsed.extracted_entities.get("similar_to_movie", "")),
                    "movies_found": len(results),
                    "scoring_weights": similarity_details.get("weights", {
                        "genre": 5.0,
                        "actor": 3.0,
                        "director": 2.0,
                        "era": 1.0
                    }),
                    "top_matches": [
                        {
                            "title": r.get("title"),
                            "score": f"{r.get('similarity_score', r.get('_score', 0)):.1f}",
                            "reason": r.get("_match_reason", "")[:80]
                        }
                        for r in results[:3]
                    ]
                }
            }
            reasoning["similarity_search"] = {
                "source_movie": similarity_details.get("source_movie", ""),
                "method": "Multi-hop graph traversal",
                "scoring": "genres (Ã—5) + actors (Ã—3) + director (Ã—2) + era (Ã—1)"
            }
            reasoning["steps"].append(sim_step)
            
            # Build graph visualization for similarity
            reasoning["graph_traversal"] = self._build_similarity_visualization(
                similarity_details, results
            )
        else:
            # Graph query step
            graph_step = {
                "step": 2,
                "name": "Knowledge Graph Query",
                "description": "Executed Cypher query on Neo4j graph database",
                "result": {
                    "movies_found": len(results),
                    "query_type": self._get_graph_query_type(parsed)
                }
            }
            reasoning["steps"].append(graph_step)
            
            # Build graph visualization
            reasoning["graph_traversal"] = self._build_graph_visualization(parsed, results)
        
        # Summary
        if parsed.query_type == QueryType.SIMILAR:
            reasoning["summary"] = f"Found movies similar to '{parsed.extracted_entities.get('similar_to_movie', '')}' using graph relationships"
        elif parsed.extracted_entities.get("director"):
            reasoning["summary"] = f"Used graph query: (Director)-[:DIRECTED]->(Movie)"
        elif parsed.extracted_entities.get("actor"):
            reasoning["summary"] = f"Used graph query: (Actor)-[:ACTED_IN]->(Movie)"
        elif parsed.extracted_entities.get("genres"):
            reasoning["summary"] = f"Used graph query: (Movie)-[:HAS_GENRE]->(Genre)"
        else:
            reasoning["summary"] = "Combined graph query on Neo4j database"
        
        reasoning["total_time_ms"] = int(elapsed * 1000)
        
        return reasoning
    
    def _build_unsupported_reasoning(
        self,
        parsed: ParsedQuery,
        elapsed: float
    ) -> Dict[str, Any]:
        """Build reasoning for unsupported queries."""
        return {
            "steps": [
                {
                    "step": 1,
                    "name": "Gemini Query Analysis",
                    "description": "Analyzed query to determine if it can be answered",
                    "result": {
                        "supported": False,
                        "reason": parsed.unsupported_reason,
                        "detected_type": parsed.explanation
                    }
                }
            ],
            "graph_traversal": None,
            "similarity_search": None,
            "gemini_analysis": {
                "model": "gemini-1.5-flash",
                "query_type": "unsupported",
                "reason": parsed.unsupported_reason
            },
            "summary": f"Query not supported: {parsed.explanation}",
            "total_time_ms": int(elapsed * 1000)
        }
    
    def _get_graph_query_type(self, parsed: ParsedQuery) -> str:
        """Get description of graph query type."""
        entities = parsed.extracted_entities
        if entities.get("director"):
            return "Director â†’ Movie relationship"
        elif entities.get("actor"):
            return "Actor â†’ Movie relationship"
        elif entities.get("genres"):
            return "Movie â†’ Genre relationship"
        elif entities.get("year_min") or entities.get("year_max"):
            return "Movie property filter (year)"
        return "Combined relationship query"
    
    def _build_graph_visualization(
        self,
        parsed: ParsedQuery,
        results: List[Dict]
    ) -> Dict[str, Any]:
        """Build a simple graph visualization structure."""
        nodes = []
        edges = []
        entities = parsed.extracted_entities
        
        # Add central entity node
        if entities.get("director"):
            director = entities["director"]
            nodes.append({
                "id": f"director_{director}",
                "label": director,
                "type": "Director",
                "color": "#e9731d"
            })
            for r in results[:5]:
                movie_id = f"movie_{r.get('movie_id')}"
                nodes.append({
                    "id": movie_id,
                    "label": r.get("title"),
                    "type": "Movie",
                    "color": "#3b82f6"
                })
                edges.append({
                    "from": f"director_{director}",
                    "to": movie_id,
                    "label": "DIRECTED"
                })
        
        elif entities.get("actor"):
            actor = entities["actor"]
            nodes.append({
                "id": f"actor_{actor}",
                "label": actor,
                "type": "Actor",
                "color": "#10b981"
            })
            for r in results[:5]:
                movie_id = f"movie_{r.get('movie_id')}"
                nodes.append({
                    "id": movie_id,
                    "label": r.get("title"),
                    "type": "Movie",
                    "color": "#3b82f6"
                })
                edges.append({
                    "from": f"actor_{actor}",
                    "to": movie_id,
                    "label": "ACTED_IN"
                })
        
        elif entities.get("genres"):
            for genre in entities["genres"][:2]:
                nodes.append({
                    "id": f"genre_{genre}",
                    "label": genre,
                    "type": "Genre",
                    "color": "#8b5cf6"
                })
            for r in results[:5]:
                movie_id = f"movie_{r.get('movie_id')}"
                if not any(n["id"] == movie_id for n in nodes):
                    nodes.append({
                        "id": movie_id,
                        "label": r.get("title"),
                        "type": "Movie",
                        "color": "#3b82f6"
                    })
                for genre in (r.get("genres") or [])[:2]:
                    if f"genre_{genre}" in [n["id"] for n in nodes]:
                        edges.append({
                            "from": movie_id,
                            "to": f"genre_{genre}",
                            "label": "HAS_GENRE"
                        })
        
        return {
            "nodes": nodes,
            "edges": edges,
            "cypher_query": self._get_cypher_query(parsed)
        }
    
    def _build_similarity_visualization(
        self,
        similarity_details: Dict,
        results: List[Dict]
    ) -> Dict[str, Any]:
        """Build graph visualization for similarity search."""
        nodes = []
        edges = []
        
        source_movie = similarity_details.get("source_movie", "Source Movie")
        
        # Add source movie node
        nodes.append({
            "id": "source_movie",
            "label": source_movie,
            "type": "Source",
            "color": "#f59e0b"  # Amber for source
        })
        
        # Add result movie nodes with their relationship types
        for r in results[:5]:
            movie_id = f"movie_{r.get('movie_id')}"
            
            # Determine strongest connection type
            shared_genres = r.get("shared_genres", [])
            shared_actors = r.get("shared_actors", [])
            shared_directors = r.get("shared_directors", [])
            
            nodes.append({
                "id": movie_id,
                "label": r.get("title"),
                "type": "Movie",
                "color": "#3b82f6"
            })
            
            # Add edges for relationships
            if shared_directors:
                edges.append({
                    "from": "source_movie",
                    "to": movie_id,
                    "label": f"Same director: {shared_directors[0]}"
                })
            elif shared_actors:
                edges.append({
                    "from": "source_movie",
                    "to": movie_id,
                    "label": f"Shared actor: {shared_actors[0]}"
                })
            elif shared_genres:
                edges.append({
                    "from": "source_movie",
                    "to": movie_id,
                    "label": f"Genre: {shared_genres[0]}"
                })
            else:
                edges.append({
                    "from": "source_movie",
                    "to": movie_id,
                    "label": "Similar era"
                })
        
        # Build the Cypher query representation
        cypher_query = f"""// Find movies similar to '{source_movie}'
MATCH (source:Movie {{title: '{source_movie}'}})

// Score by shared relationships
OPTIONAL MATCH (source)-[:HAS_GENRE]->(g:Genre)<-[:HAS_GENRE]-(similar)
OPTIONAL MATCH (source)<-[:ACTED_IN]-(a:Actor)-[:ACTED_IN]->(similar)  
OPTIONAL MATCH (source)<-[:DIRECTED]-(d:Director)-[:DIRECTED]->(similar)

WITH similar, 
     count(DISTINCT g) * 5 +  // Genre weight
     count(DISTINCT a) * 3 +  // Actor weight
     count(DISTINCT d) * 2    // Director weight
     AS score

RETURN similar.title, score
ORDER BY score DESC"""
        
        return {
            "nodes": nodes,
            "edges": edges,
            "cypher_query": cypher_query
        }
    
    def _get_cypher_query(self, parsed: ParsedQuery) -> str:
        """Get the Cypher query that was used."""
        entities = parsed.extracted_entities
        
        if entities.get("director"):
            return f"""MATCH (d:Director)-[:DIRECTED]->(m:Movie)
WHERE d.name =~ '(?i).*{entities["director"]}.*'
RETURN m.title, m.vote_average
ORDER BY m.vote_average DESC"""
        elif entities.get("actor"):
            return f"""MATCH (a:Actor)-[:ACTED_IN]->(m:Movie)
WHERE a.name =~ '(?i).*{entities["actor"]}.*'
RETURN m.title, m.vote_average
ORDER BY m.vote_average DESC"""
        elif entities.get("genres"):
            return f"""MATCH (m:Movie)-[:HAS_GENRE]->(g:Genre)
WHERE g.name IN {entities["genres"]}
RETURN m.title, m.vote_average
ORDER BY m.vote_average DESC"""
        return "MATCH (m:Movie) RETURN m ORDER BY m.popularity DESC"
    
    def clear_cache(self):
        """Clear the response cache."""
        self._response_cache.clear()
        logger.info("Response cache cleared")


# Singleton instance
smart_rag_service = SmartRAGService()
